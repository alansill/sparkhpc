#!/bin/sh
#BSUB -J spark_notebook
#BSUB -W 01:00 # requesting one hour 
#BSUB -n 10 # requesting 10 cores for the driver
#BSUB -Is

source /cluster/apps/spark/scripts/setup_spark.sh

# the next line assumes that you have 2 Gb/core -- it gives 70% of the available memory to the JVM that runs the driver
DRIVER_MEM=$(printf '%.f' $(echo "$LSB_DJOB_NUMPROC * 2 * .7" | bc))G

# if you want to specify other options for spark, add them to the spark_options string 
# to specify a spark configuration directory, use the --spark_config flag 
python /cluster/apps/spark/scripts/start_notebook.py --spark --spark_options "--driver-memory ${DRIVER_MEM}" 
